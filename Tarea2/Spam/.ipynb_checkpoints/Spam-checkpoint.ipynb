{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam\n",
    "A partir de la base de datos de spam con vectores de características de 2000 dimensiones contenidasen el archivo\n",
    "spam.csv:\n",
    "\n",
    "* Entrena diferentes clasificadores despam usando clasificadores bayesianos ingenuos con distintas distribuciones\n",
    "* Binariza los vectores de características y entrena los mismos clasificadores con esta representación\n",
    "* Evalúa los clasificadores entrenados usando tanto los mismos datos de entrenamiento como datos distintos\n",
    "* Reporta y explica el desempeño de los diferentes clasificadores\n",
    "\n",
    "El archivo spam.csv contiene 2001 atributos por cada renglón, de los cuales los primeros 2000 corresponden al vector de características de un correo y el último corresponde a la clase, esto es, 1 si es spam y 0 si no lo es. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a generar un clasificador bayesiano ingenuo considerando una distribución del tipo multinomial ya que por la naturaleza de los datos consideramos que esta distribución es la que se mejor se adapta por otra vamos a considerar todo el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de aciertos es el siguiente:\n",
      "95.3402938902%\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "#Carga de los datos:\n",
    "data_set = pd.read_csv(\"spam.csv\",delim_whitespace=True,header=None)\n",
    "\n",
    "X = data_set.ix[:,0:1999].as_matrix()\n",
    "y = data_set.ix[:, 2000].as_matrix()\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "predicciones = clf.predict(X)\n",
    "\n",
    "predicciones = predicciones.astype(int)\n",
    "\n",
    "aciertos=0.0\n",
    "total_datos= float(data_set.shape[0])\n",
    "#print total_datos\n",
    "\n",
    "for ind in range(len(predicciones)):\n",
    "    if int(predicciones[ind])==int(y[ind]):\n",
    "        aciertos+=1\n",
    "\n",
    "\n",
    "#El porcentaje de aciertos es el siguiente:\n",
    "print \"El porcentaje de aciertos es el siguiente:\"\n",
    "print str((aciertos/total_datos)*100)+\"%\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el rendimiento de nuestro clasificador es muy bueno. Lo que vamos hacer a continuación es volver a generar un clasificador con las mismas caracteristacas\n",
    "cona la diferencia de que utilizaremos un 80% de los datos para entrenar y un 20% para probar nuestro \n",
    "clasificador. Y veremos el rendimiento con esta cantidad de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de aciertos es el siguiente:\n",
      "57.3913043478%\n"
     ]
    }
   ],
   "source": [
    "# Separar el conjunto de datos para training y para test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data_set, test_size = 0.2)\n",
    "\n",
    "X = train.ix[:,0:1999].as_matrix()\n",
    "y = train.ix[:, 2000].as_matrix()\n",
    "\n",
    "\n",
    "to_predict = test.ix[:,0:1999].as_matrix()\n",
    "to_predict_val = test.ix[:,2000].as_matrix()\n",
    "\n",
    "#print to_predict_val\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "predicciones = clf.predict(to_predict)\n",
    "predicciones = predicciones.astype(int)\n",
    "\n",
    "aciertos=0.0\n",
    "total_datos= float(to_predict_val.shape[0]) \n",
    "\n",
    "for ind in range(len(predicciones)):\n",
    "    if int(predicciones[ind])==int(y[ind]):\n",
    "        aciertos+=1\n",
    "\n",
    "#El porcentaje de aciertos es el siguiente:\n",
    "print \"El porcentaje de aciertos es el siguiente:\"\n",
    "print str((aciertos/total_datos)*100)+\"%\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar el rendimiento de nuestro clasificador baja debido a que bajamos la cantidad de \n",
    "datos para entrenar a nuestro clasificador. Por otra parte lo que vamos hacer ahora es binarizar y aplicar \n",
    "una distribución del tipo Bernoulli y comparar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de aciertos es el siguiente:\n",
      "90.84213%\n"
     ]
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer().fit(X)\n",
    "bina=binarizer.transform(X)\n",
    "\n",
    "X = bina\n",
    "y = data_set.ix[:, 2000].as_matrix()\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "predicciones = clf.predict(X)\n",
    "\n",
    "predicciones = predicciones.astype(int)\n",
    "\n",
    "aciertos=0.0\n",
    "total_datos= float(data_set.shape[0])\n",
    "print total_datos\n",
    "\n",
    "for ind in range(len(predicciones)):\n",
    "    if int(predicciones[ind])==int(y[ind]):\n",
    "        aciertos+=1\n",
    "\n",
    "\n",
    "#El porcentaje de aciertos es el siguiente:\n",
    "print \"El porcentaje de aciertos es el siguiente:\"\n",
    "print str((aciertos/total_datos)*100)+\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar el rendimiento de nuestro clasificador baja debido que al momento de binarizar \n",
    "estamos perdiendo información para nuestro clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando otra distribución:\n",
    "Ahora lo que vamos hacer es usar otro tipo de distribución y ver el rendimiento que genera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de aciertos es el siguiente:\n",
      "92.807424594%\n"
     ]
    }
   ],
   "source": [
    "#Carga de los datos:\n",
    "data_set = pd.read_csv(\"spam.csv\",delim_whitespace=True,header=None)\n",
    "\n",
    "X = data_set.ix[:,0:1999].as_matrix()\n",
    "y = data_set.ix[:, 2000].as_matrix()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "predicciones = clf.predict(X)\n",
    "\n",
    "predicciones = predicciones.astype(int)\n",
    "\n",
    "aciertos=0.0\n",
    "total_datos= float(data_set.shape[0])\n",
    "#print total_datos\n",
    "\n",
    "for ind in range(len(predicciones)):\n",
    "    if int(predicciones[ind])==int(y[ind]):\n",
    "        aciertos+=1\n",
    "\n",
    "\n",
    "#El porcentaje de aciertos es el siguiente:\n",
    "print \"El porcentaje de aciertos es el siguiente:\"\n",
    "print str((aciertos/total_datos)*100)+\"%\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones:\n",
    "\n",
    "Por lo tanto vemos que el rendimiento tanto de binarizar como en el caso anterior de usar una distribución normal bajan el rendimiento de nuestro clasificador por una parte al momento de binarizar perdemos datos y por otra parte vemos que al forzar nuestro conjunto de datos a una distribución del tipo normal esta no se\n",
    "adecua de manera correcta provocando que el rendimiento de nuestro clasificador baje. En este caso el usar \n",
    "la distribución Multinomial es la que ha dado un mejor rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
